{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DNN multi-class classifier\n",
    "Let’s say we have a set of body measurements (height and weight, for instance) and the gender associated with each set of measurements, and we want to predict whether someone is a baby, toddler, preteen, teenager, or adult. We want our model to classify, or predict, from more than one class or label—in this example, we have a total of five classes of age categories. To do this, we can use another form of a DNN, called a multiclass classifier.\n",
    "\n",
    "We can already see we will have some complications. For example, men on average as adults are taller than women. But during the preteen years, girls tend to be taller than boys. We know on average that men get heavier early in their adult years in comparison to their teenage years, but women on average are less likely to become heavier. So we should anticipate problems in predicting around the preteen years for girls, teenage years for boys, and adult years for women.\n",
    "\n",
    "These problems are examples of nonlinearity; the relationship between a feature and a prediction is not linear. Instead, the relationship can be broken into segments of disjointed linearity. This is the type of problem neural networks are good at.\n",
    "\n",
    "<img src=\"img_5.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code shows an example of constructing a multiclass classifier DNN. We start by setting up our input and output layers with the multiple features and multiple classes, respectively. Then we change the activation function from sigmoid to softmax. Next we set our loss function to categorical_crossentropy. This is generally the most recommended for a multiclass classification.\n",
    "\n",
    "\n",
    "The following code shows an example of constructing a multiclass classifier DNN. We start by setting up our input and output layers with the multiple features and multiple classes, respectively. Then we change the activation function from sigmoid to softmax. Next we set our loss function to categorical_crossentropy. This is generally the most recommended for a multiclass classification.\n",
    "\n",
    "Finally, we will use a popular and widely used variant of gradient descent called the Adam optimizer (adam). Adam incorporates several aspects of other methods, such as rmsprop (root mean square) and adagrad (adaptive gradient), along with an adaptive learning rate. It’s generally considered the best-in-class optimizer for a wide variety of neural networks:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input\n",
    "from keras import Model, Sequential"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sequential API"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                140       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 305\n",
      "Trainable params: 305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(10, activation=\"relu\", input_shape=(13,)),\n",
    "    Dense(10, activation=\"relu\"),\n",
    "    Dense(5, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functional API"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 13)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                140       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 305\n",
      "Trainable params: 305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "functional_input = Input((13,))\n",
    "X = Dense(10, activation=\"relu\")(functional_input)\n",
    "X = Dense(10, activation=\"relu\")(X)\n",
    "functional_output = Dense(5, activation=\"softmax\")(X)\n",
    "functional_model = Model(functional_input, functional_output)\n",
    "functional_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "functional_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}