{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Natural language understanding\n",
    "Let’s start by taking a look at the general model architecture for NLU in figure 5.20. In NLU, the model learns to understand the text and learns to perform a task based on that understanding. Examples of tasks include classifying the text, sentiment analysis, and entity extraction.\n",
    "\n",
    "<img src=\"img.png\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An NLU model is decomposed into the same components that make up all deep learning models: stem, learner, and task. The differences lie in what happens in each component.\n",
    "\n",
    "In an NLU model, the stem consists of\n",
    "1. An encoder. Its purpose is to convert the string representation of the text into a numeric-based vector, referred to as an embedding.\n",
    "2. This embedding is of a higher dimensionality than the string input and contains richer contextual information about the words, or characters, or sentences.\n",
    "3. The stem encoder is actually another model that has been pretrained. Think of the stem encoder as a dictionary. For each word, the low dimensionality, it outputs all the possible meanings, the high dimensionality. A common example of an embedding is a vector of N dimensions, in which each element represents another word, and the value\n",
    "indicates how closely this word is related to the other word.\n",
    "\n",
    "Next, the embeddings are passed to the learner component. In an NLU model, the learner consists of one or more encoder groups, which consist, in turn, of one or more encoder blocks. Each of these blocks is based on a design pattern, such as a attention block in a transformer model, and the assembly of the blocks and groups is based on design principles for encoder patterns.\n",
    "\n",
    "\n",
    "You probably notice that both the stem and learner refer to an encoder. They are not the same type of encoder in each component. Having the same name for two different things can be a bit confusing, so I’ll clarify. When we talk about the encoder that generates embeddings, we will refer to it as the stem encoder; otherwise, we are referring to the encoder in the learner.\n",
    "\n",
    "The purpose of the encoder in the learner is to convert the embeddings to a lower dimensionality representation of the meaning of the text, which is called an intermediate representation. This is comparable to learning the essential features in an image in a CNN.\n",
    "\n",
    "#  Transformer architecture\n",
    "\n",
    "The Transformer architecture addressed a challenging problem in NLU: how to handle text sequences that are essentially comparable to a time-series—that is, the meaning is dependent on the sequence ordering of the words. Previously to the Transformer architecture, NLU models were implemented as recurrent neural networks (RNNs), which would retain the sequence ordering of the text and learn the importance (long memory) or non-importance (short memory) of the words.\n",
    "\n",
    "What the Transformer model did is introduce a new mechanism called attention that transformed NLU models from a time-series to a spatial model. Instead of looking at words, or characters, or sentences as a sequence, we take a chunk of words and represent them spatially, like an image. The model learns to extract essential context—the features. The attention mechanism acts similarly to the identity link in a residual network. It adds attention—weight—to the contexts that are more important.\n",
    "\n",
    "\n",
    "Figure 5.21 shows an attention block in a transformer architecture. The input to the block is a set of context maps, comparable to feature maps, from the previous block. The attention mechanism adds weight to portions of the context block that are more important to the contextual understanding (indicating to pay attention here). The attention context maps are then passed to a feed-forward layer that outputs the next set of context maps\n",
    "\n",
    "<img src=\"img_1.png\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}