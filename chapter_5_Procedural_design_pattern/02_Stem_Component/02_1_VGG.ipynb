{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# VGG\n",
    "The VGG architecture, winner of the 2014 ImageNet ILSVRC contest for image classification, is considered the father of modern CNNs, while AlexNet is considered the\n",
    "grandfather. VGG formalized the concept of constructing a CNN into components and groups by using a pattern. Prior to VGG, CNNs were constructed as ConvNets, whose usefulness did not go beyond academic novelties.\n",
    "\n",
    " VGGs were the first to have practical applications in production. For several years after its development, researchers continued to compare more modern SOTA architecture developments to the VGG and to use VGGs for the classification backbone of early SOTA object-detection models\n",
    "\n",
    "The VGG, along with Inception, formalized the concept of having a first convolutional group that did a coarse-level feature extraction, which we now refer to as the\n",
    "stem component. Subsequent convolutional groups would then do **finer levels of feature extraction and feature learning**, which we now refer to as **representational learning**, and hence the term learner for this second major component\n",
    "\n",
    " Researchers eventually discovered a drawback of a VGG stem: it retained the size of the input (224 × 224) in the extracted coarse feature maps, resulting in an unnecessary number of parameters entering the learner. The quantity of parameters both increased the memory footprint as well as reduced performance for training and prediction. Researchers subsequently addressed this problem in later SOTA models by adding pooling in the stem component, reducing the output size of the coarse-level\n",
    "feature maps. This change decreased memory footprint while increasing performance, without a loss in accuracy.\n",
    "\n",
    "The VGG stem component, depicted in figure 5.3, was designed to take as an input a 224 × 224 × 3 image and to output 64 feature maps, each 224 × 224 in size. In other\n",
    "words, the VGG stem group did not do any size reduction of the feature maps.\n",
    "\n",
    "<img src=\"img.png\">/\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "def stem(inputs):\n",
    "    \"\"\"\n",
    "    Construct a Stem Convolution Group\n",
    "    inputs: input tensor\n",
    "    \"\"\"\n",
    "    outputs = Conv2D(64, kernel_size=(3,3), strides=(1, 1), padding=\"same\",  activation=\"relu\")(inputs)\n",
    "    return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}