{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet networks\n",
    "The ResNet type of CNN was designed by Microsoft Research to compete in the international ILSVRC competition. The ResNet in the 2015 contest took first place in all categories for the ImageNet and Common Objects in Context (COCO) competition.\n",
    "\n",
    " The VGGNet design pattern covered in the previous section had limitations in how deep the model architecture could go in layers, before suffering from vanishing and exploding gradients.\n",
    "\n",
    "\n",
    "The researchers for the residual block design pattern component of the residual network proposed a new novel layer connection they called an identity link. The identity link introduced the earliest concept of feature reuse. Prior to the identity link, each convolutional block did feature extraction on the previous convolutional output, without retaining any knowledge from prior outputs.\n",
    "\n",
    "Concurrently along with ResNet, other researchers—such as at Google, with Inception v1 (GoogLeNet)—further refined convolutional design patterns into groups and blocks. In parallel to these design improvements was the introduction of batch normalization.\n",
    "\n",
    " Using identity links along with batch normalization provided more stability across layers, reducing both vanishing and exploding gradients and divergence between\n",
    "layers, allowing model architectures to go deeper in layers to increase accuracy in prediction.\n",
    "\n",
    "## Architecture\n",
    "ResNet, and other architectures within this class, use different **layer-to-layer** connection patterns.The patterns we’ve discussed so far (ConvNet and VGG) use the fully connected layer-to-layer pattern.\n",
    "\n",
    "ResNet34 introduced a new block layer and layer-connection pattern,\n",
    "* residual blocks, and\n",
    "* identity connection, respectively.\n",
    "\n",
    "Each block has an identity connection that creates a parallel path between the input of the residual block and its output, as depicted in figure 3.11. As in VGG, each successive block doubles the number of filters. Pooling is done at the end of the sequence of block\n",
    "\n",
    "<img src=\"img_12.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One of the problems with neural networks is that as we add deeper layers (under the presumption of increasing accuracy), their performance can degrade. It can get\n",
    "worse, not better. This occurs for several reasons.\n",
    "\n",
    "1. As we go deeper, we are adding more parameters (weights). The more parameters, the more places that each input in the training data will fit to the excess parameters. Instead of generalizing, the neural network will simply learn each training example (rote memorization). (1)\n",
    "2. The other issue is **covariate shift**: the distribution of the weights will widen (spread further apart) as we go deeper, resulting in making it more difficult for the neural network to converge. (2)\n",
    "\n",
    "The former case (1) causes a degradation in performance on the test (holdout) data, and the latter (2), on the training data as well as a vanishing or exploding gradient.\n",
    "\n",
    "Residual blocks allow neural networks to be built with deeper layers without a degradation in performance on the test data.\n",
    "\n",
    "A ResNet block could be viewed as a VGG block with the addition of the identity link. While the VGG style of the block performs feature detection, the identity link retains the input for the next subsequent block, whereby the input to the next block consists of both the previous features’ detection and input.\n",
    "\n",
    " By retaining information from the past (previous input), this block design allows neural networks to go deeper than the VGG counterpart, with an increase in accuracy\n",
    "\n",
    "VGG: h(x) = f(x, {W})\n",
    "ResNet: h(x) = f(x, {W}) + x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from keras import Model, Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D, ReLU, BatchNormalization, Flatten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def resnet_blk_example(X, num_filters):\n",
    "    short_cut = X\n",
    "    X = Conv2D(num_filters, activation=\"relu\")(X)\n",
    "    X = Conv2D(num_filters, activation=\"relu\")(X)\n",
    "    X = layers.add([short_cut, X])\n",
    "    return X\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"img_13.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The ResNet architectures take as input a (224, 224, 3) vector—an RGB image (3 channels) of 224 (height) × 224 (width) pixels. The first layer is a basic convolutional layer, consisting of a convolution using a fairly large filter size of 7 × 7. The output (feature maps) is then reduced in size by a max pooling layer.\n",
    "\n",
    " After the initial convolutional layer is a succession of groups of residual blocks. Each successive group doubles the number of filters (similar to VGG). Unlike VGG, though, there is no pooling layer between the groups that would reduce the size of the feature maps.\n",
    "\n",
    "  The input to the next block has a shape based on the previous block’s filter size (let’s call it X). The next block, by doubling the filters, will cause the output of that residual block to be double in size (let’s call it 2X). The identity link would attempt to add the input matrix (X) and the output matrix (2X). Yikes—we get an error, indicating we can’t broadcast (for the add operation) matrices of different sizes.  For ResNet, this is solved by adding a convolutional block between each “doubling” group of residual blocks. As depicted in figure 3.12, the convolutional block **doubles the filters** to **reshape the siz** and **doubles the stride** to **reduce the feature map** size by 75% (performs feature pooling).\n",
    "\n",
    "<img src=\"img_14.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def residual_block(n_filters, X):\n",
    "    short_cut = X\n",
    "    X = Conv2D(n_filters, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation=\"relu\")(X)\n",
    "    X = Conv2D(n_filters, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation=\"relu\")(X)\n",
    "    X = layers.add([short_cut, X])\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def conv_block(n_filters, X):\n",
    "    X = Conv2D(n_filters, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\")(X)\n",
    "    X = Conv2D(n_filters, kernel_size=(3,3), strides=(2,2), padding=\"same\", activation=\"relu\")(X)\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 224, 224, 64  9472        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 112, 112, 64  0          ['conv2d_29[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 112, 112, 64  36928       ['max_pooling2d_1[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 112, 112, 64  36928       ['conv2d_30[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 112, 112, 64  0           ['max_pooling2d_1[0][0]',        \n",
      "                                )                                 'conv2d_31[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 112, 112, 64  36928       ['add_11[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 112, 112, 64  36928       ['conv2d_32[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 112, 112, 64  0           ['add_11[0][0]',                 \n",
      "                                )                                 'conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 112, 112, 12  73856       ['add_12[0][0]']                 \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 112, 112, 12  147584      ['conv2d_34[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 112, 112, 12  147584      ['conv2d_35[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 112, 112, 12  147584      ['conv2d_36[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 112, 112, 12  0           ['conv2d_35[0][0]',              \n",
      "                                8)                                'conv2d_37[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 112, 112, 12  147584      ['add_13[0][0]']                 \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 112, 112, 12  147584      ['conv2d_38[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 112, 112, 12  0           ['add_13[0][0]',                 \n",
      "                                8)                                'conv2d_39[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 112, 112, 12  147584      ['add_14[0][0]']                 \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 112, 112, 12  147584      ['conv2d_40[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 112, 112, 12  0           ['add_14[0][0]',                 \n",
      "                                8)                                'conv2d_41[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 112, 112, 25  295168      ['add_15[0][0]']                 \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 112, 112, 25  590080      ['conv2d_42[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 112, 112, 25  590080      ['conv2d_43[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 112, 112, 25  590080      ['conv2d_44[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 112, 112, 25  0           ['conv2d_43[0][0]',              \n",
      "                                6)                                'conv2d_45[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 112, 112, 25  590080      ['add_16[0][0]']                 \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 112, 112, 25  590080      ['conv2d_46[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 112, 112, 25  0           ['add_16[0][0]',                 \n",
      "                                6)                                'conv2d_47[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 112, 112, 25  590080      ['add_17[0][0]']                 \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 112, 112, 25  590080      ['conv2d_48[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 112, 112, 25  0           ['add_17[0][0]',                 \n",
      "                                6)                                'conv2d_49[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 112, 112, 51  1180160     ['add_18[0][0]']                 \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 112, 112, 51  2359808     ['conv2d_50[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 112, 112, 51  2359808     ['conv2d_51[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 112, 112, 51  2359808     ['conv2d_52[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 112, 112, 51  0           ['conv2d_51[0][0]',              \n",
      "                                2)                                'conv2d_53[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 112, 112, 51  2359808     ['add_19[0][0]']                 \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 112, 112, 51  2359808     ['conv2d_54[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 112, 112, 51  0           ['add_19[0][0]',                 \n",
      "                                2)                                'conv2d_55[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 112, 112, 51  2359808     ['add_20[0][0]']                 \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 112, 112, 51  2359808     ['conv2d_56[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 112, 112, 51  0           ['add_20[0][0]',                 \n",
      "                                2)                                'conv2d_57[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['add_21[0][0]']                 \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1000)         513000      ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,901,672\n",
      "Trainable params: 23,901,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_input = Input((224, 224, 3))\n",
    "X = Conv2D(64, kernel_size=(7,7), strides=(1,1), padding=\"same\", activation=\"relu\")(resnet_input)\n",
    "X = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(X)\n",
    "\n",
    "for _ in range(2):\n",
    "    X = residual_block(64, X)\n",
    "\n",
    "X = conv_block(128, X)\n",
    "\n",
    "for _ in range(3):\n",
    "    X = residual_block(128, X)\n",
    "\n",
    "X = conv_block(256, X)\n",
    "\n",
    "for _ in range(3):\n",
    "    X = residual_block(256, X)\n",
    "\n",
    "X = conv_block(512, X)\n",
    "\n",
    "for _ in range(3):\n",
    "    X = residual_block(512, X)\n",
    "\n",
    "X = GlobalAveragePooling2D()(X)\n",
    "resnet_output = Dense(1000, activation='softmax')(X)\n",
    "resnet_model = Model(resnet_input, resnet_output)\n",
    "resnet_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let’s now run model.summary(). We see that the total number of parameters to learn is 21 million. This is in contrast to the VGG16, which has 138 million parameters. So the ResNet architecture is six times computationally faster. This reduction is mostly achieved by the construction of the residual blocks. Notice that the DNN backend is just a single output Dense layer. In effect, there is no backend. The early residual block groups act as the CNN frontend doing the feature detection, while the latter residual blocks perform the classification. In doing so, unlike in VGG, there was no need for several fully connected dense layers, which would have substantially increased the number of parameters.\n",
    "\n",
    " Unlike the previous example of pooling, in which the size of each feature map is reduced according to the size of the stride, GlobalAveragePooling2D is like a supercharged version of pooling:\n",
    "1. each feature map is replaced by a single value, which in this case is the average of all values in the corresponding feature map.\n",
    "2. For example, if the input is 256 feature maps, the output will be a 1D vector of size 256.\n",
    "\n",
    "After ResNet, it became the general practice for deep convolutional neural networks to use GlobalAveragePooling2D at the last pooling stage, which benefited from a substantial reduction of the number of parameters coming into the classifier, without significant loss in representational power.\n",
    "\n",
    "Another advantage is the identity link, which provided the ability to add deeper layers, without degradation, for higher accuracy.\n",
    "\n",
    "\n",
    " ResNet50 introduced a variation of the residual block referred to as the **bottleneck residual block**. In this version, the group of two 3 × 3 convolutional layers is replaced by a group of 1 × 1, then 3 × 3, and then 1 × 1 convolutional layers. The first 1 × 1 convolution performs a dimensionality reduction, reducing the computational complexity, and the last convolution restores the dimensionality, increasing the number of filters by a factor of 4. The middle 3 × 3 convolution is referred to as the bottleneck convolution, like the neck of a bottle. The bottleneck residual block, depicted in figure 3.13, allows\n",
    "for deeper neural networks, without degradation, and further reduction in computational complexity.\n",
    "\n",
    "<img src=\"img_15.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def bottleneck_block(n_filters, X):\n",
    "    short_cut = X\n",
    "    X = Conv2D(n_filters, kernel_size=(1,1), strides=(1,1), padding=\"same\", activation=\"relu\")(X)\n",
    "    X = Conv2D(n_filters, kernel_size=(3,3), strides=(1,1), padding=\"same\", activation=\"relu\")(X)\n",
    "    X = Conv2D(n_filters*4, kernel_size=(1,1), strides=(1,1), padding=\"same\", activation=\"relu\")(X)\n",
    "    X =layers.add([short_cut, X])\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Residual blocks introduced the concepts of representational power and representational equivalence.\n",
    "\n",
    "1. **Representational power** is a measure of how powerful a block is as a *feature extractor*\n",
    "2. **Representational equivalence** is the idea that a block can be factored into a **lower computational complexity**, while **maintaining representational power**.\n",
    "\n",
    "\n",
    "# Batch normalization\n",
    "Another problem with adding deeper layers in a neural network is the vanishing gradient problem. This is actually about computer hardware. During training (the process of backward propagation and gradient descent), at each layer the weights are multiplied by very small numbers—specifically, numbers less than 1. As you know, two numbers less than 1 multiplied together make an even smaller number. When these tiny values are propagated through deeper layers, they continuously get smaller. At some point, the computer hardware can’t represent the value anymore—hence, the vanishing gradient.\n",
    "\n",
    "The problem is further exacerbated if we try to use half-precision floats (16-bit floats) for the matrix operations versus single-precision floats (32-bit floats). The advantage of the former is that the weights (and data) are stored in half the amount of space—and using a general rule of thumb, by reducing the computational size in half, we can execute four times as many instructions per computing cycle. The problem, of course, is that with even smaller precision, we will encounter the vanishing gradient even sooner.\n",
    "\n",
    "\n",
    "Batch normalization is a technique applied to the output of a layer (before or after the activation function). Without going into the statistics aspect, it normalizes the shift in the weights as they are being trained. This has several advantages:\n",
    "1. it smooths out (across a batch) the amount of change, thus slowing the possibility of getting a number so small that it can’t be represented by the hardware.\n",
    "2. Additionally, by narrowing the amount of shift between the weights, convergence can happen sooner by using a higher learning rate and reducing the overall amount of training time.\n",
    "\n",
    "In earlier implementations, batch normalization was implemented post-activation.\n",
    "The batch normalization would occur after the convolution and dense layers. At the time, it was debated whether the batch normalization should be before or after the activation function.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model_sample = Sequential([\n",
    "    Conv2D(64, kernel_size=3, strides=2, padding=\"same\",input_shape=(128, 128, 3)),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    Flatten(),\n",
    "    Dense(1024),\n",
    "    ReLU(),\n",
    "    BatchNormalization()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ResNet50\n",
    "ResNet50 is a well-known model, which is commonly reused as a stock model, such as for transfer learning, as shared layers in objection detection, and for performance benchmarking. The model has three versions: v1, v1.5 and v2.\n",
    "\n",
    "ResNet50 v1 formalized the concept of a convolutional group. This is a set of convolutional blocks that share a common configuration, such as the number of filters. In v1, the neural network is decomposed into groups, and each group doubles the number of filters from the previous group.\n",
    "\n",
    "Additionally, the concept of a separate convolution block to double the number of filters was removed and replaced by a residual block that uses linear projection. Each group starts with a residual block using linear projection on the identity link to double the number of filters, while the remaining residual blocks pass the input directly to the output for the matrix add operation. Additionally, the first 1 × 1 convolution in the residual block with linear projection uses a **stride of 2** (feature pooling), which is also known as a **strided convolution**, reducing the feature map sizes by 75%, as depicted in figure 3.14.\n",
    "\n",
    "\n",
    "<img src=\"img_16.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following is an implementation of ResNet50 v1 using the bottleneck block combined with batch normalization:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def projection_block(n_filters,input_X, stride=(2,2)):\n",
    "    short_cut = Conv2D(n_filters*4, kernel_size=(1,1), strides=stride)(input_X)\n",
    "    short_cut = BatchNormalization()(short_cut)\n",
    "\n",
    "    hidden_X = Conv2D(n_filters, kernel_size=(1,1), strides=stride)(input_X)\n",
    "    hidden_X = BatchNormalization()(hidden_X)\n",
    "    hidden_X = ReLU()(hidden_X)\n",
    "\n",
    "    hidden_X= Conv2D(n_filters, kernel_size=(3,3), strides=(1,1), padding=\"same\")(hidden_X)\n",
    "    hidden_X = BatchNormalization()(hidden_X)\n",
    "    hidden_X = ReLU()(hidden_X)\n",
    "\n",
    "    hidden_X = Conv2D(n_filters*4, kernel_size=(1,1), strides=(1, 1))(hidden_X)\n",
    "    hidden_X = BatchNormalization()(hidden_X)\n",
    "\n",
    "    hidden_X = layers.add([short_cut, hidden_X])\n",
    "    hidden_X = ReLU()(hidden_X)\n",
    "    return hidden_X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ResNet50 v2 introduced preactivation batch normalization (BN-RE-Conv), in which the batch normalization and activation functions are placed before (instead of after) the corresponding convolution or dense layer.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def identity_block(n_filters, input_X):\n",
    "    short_cut = X\n",
    "\n",
    "    hidden_X = Conv2D(n_filters, kernel_size=(1,1), strides=(1,1))(input_X)\n",
    "    hidden_X = BatchNormalization()(hidden_X)\n",
    "    hidden_X = ReLU()(hidden_X)\n",
    "\n",
    "    hidden_X= Conv2D(n_filters, kernel_size=(3,3), strides=(1,1), padding=\"same\")(hidden_X)\n",
    "    hidden_X = BatchNormalization()(hidden_X)\n",
    "    hidden_X = ReLU()(hidden_X)\n",
    "\n",
    "    hidden_X = Conv2D(n_filters*4, kernel_size=(1,1), strides=(1, 1))(hidden_X)\n",
    "    hidden_X = BatchNormalization()(hidden_X)\n",
    "\n",
    "    hidden_X = layers.add([short_cut, hidden_X])\n",
    "    hidden_X = ReLU()(hidden_X)\n",
    "    return hidden_X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " zero_padding2d_23 (ZeroPadding  (None, 230, 230, 3)  0          ['input_16[0][0]']               \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, 112, 112, 64  9472        ['zero_padding2d_23[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 112, 112, 64  256        ['conv2d_109[0][0]']             \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)                (None, 112, 112, 64  0           ['batch_normalization_47[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " zero_padding2d_24 (ZeroPadding  (None, 114, 114, 64  0          ['re_lu_35[0][0]']               \n",
      " 2D)                            )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 56, 56, 64)  0           ['zero_padding2d_24[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 56, 56, 64)   4160        ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 56, 56, 64)  256         ['conv2d_111[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)                (None, 56, 56, 64)   0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 56, 56, 64)   36928       ['re_lu_36[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 56, 56, 64)  256         ['conv2d_112[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)                (None, 56, 56, 64)   0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 56, 56, 256)  16640       ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, 56, 56, 256)  16640       ['re_lu_37[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 56, 56, 256)  1024       ['conv2d_110[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 56, 56, 256)  1024       ['conv2d_113[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 56, 56, 256)  0           ['batch_normalization_48[0][0]', \n",
      "                                                                  'batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)                (None, 56, 56, 256)  0           ['add_30[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, 56, 56, 64)   16448       ['re_lu_38[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 56, 56, 64)  256         ['conv2d_114[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)                (None, 56, 56, 64)   0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, 56, 56, 64)   36928       ['re_lu_39[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 56, 56, 64)  256         ['conv2d_115[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)                (None, 56, 56, 64)   0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)            (None, 56, 56, 256)  16640       ['re_lu_40[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 56, 56, 256)  1024       ['conv2d_116[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 56, 56, 256)  0           ['re_lu_38[0][0]',               \n",
      "                                                                  'batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)                (None, 56, 56, 256)  0           ['add_31[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)            (None, 56, 56, 64)   16448       ['re_lu_41[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 56, 56, 64)  256         ['conv2d_117[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_42 (ReLU)                (None, 56, 56, 64)   0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)            (None, 56, 56, 64)   36928       ['re_lu_42[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 56, 56, 64)  256         ['conv2d_118[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 56, 56, 64)   0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)            (None, 56, 56, 256)  16640       ['re_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 56, 56, 256)  1024       ['conv2d_119[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 56, 56, 256)  0           ['re_lu_41[0][0]',               \n",
      "                                                                  'batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 56, 56, 256)  0           ['add_32[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, 28, 28, 128)  32896       ['re_lu_44[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 28, 28, 128)  512        ['conv2d_121[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 28, 28, 128)  512        ['conv2d_122[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)            (None, 28, 28, 512)  131584      ['re_lu_44[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, 28, 28, 512)  66048       ['re_lu_46[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_120[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_123[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 28, 28, 512)  0           ['batch_normalization_58[0][0]', \n",
      "                                                                  'batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 28, 28, 512)  0           ['add_33[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, 28, 28, 128)  65664       ['re_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 28, 28, 128)  512        ['conv2d_124[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_48[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 28, 28, 128)  512        ['conv2d_125[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, 28, 28, 512)  66048       ['re_lu_49[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_126[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 28, 28, 512)  0           ['re_lu_47[0][0]',               \n",
      "                                                                  'batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)                (None, 28, 28, 512)  0           ['add_34[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 28, 28, 128)  65664       ['re_lu_50[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 28, 28, 128)  512        ['conv2d_127[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_51[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 28, 28, 128)  512        ['conv2d_128[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, 28, 28, 512)  66048       ['re_lu_52[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_129[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 28, 28, 512)  0           ['re_lu_50[0][0]',               \n",
      "                                                                  'batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)                (None, 28, 28, 512)  0           ['add_35[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, 28, 28, 128)  65664       ['re_lu_53[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 28, 28, 128)  512        ['conv2d_130[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_54 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_54[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 28, 28, 128)  512        ['conv2d_131[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_55 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)            (None, 28, 28, 512)  66048       ['re_lu_55[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 28, 28, 512)  2048       ['conv2d_132[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, 28, 28, 512)  0           ['re_lu_53[0][0]',               \n",
      "                                                                  'batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_56 (ReLU)                (None, 28, 28, 512)  0           ['add_36[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)            (None, 14, 14, 256)  131328      ['re_lu_56[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_134[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_57 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)            (None, 14, 14, 256)  590080      ['re_lu_57[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_135[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_58 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)            (None, 14, 14, 1024  525312      ['re_lu_56[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)            (None, 14, 14, 1024  263168      ['re_lu_58[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_133[0][0]']             \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_136[0][0]']             \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_37 (Add)                   (None, 14, 14, 1024  0           ['batch_normalization_71[0][0]', \n",
      "                                )                                 'batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_59 (ReLU)                (None, 14, 14, 1024  0           ['add_37[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)            (None, 14, 14, 256)  262400      ['re_lu_59[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_137[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_60 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)            (None, 14, 14, 256)  590080      ['re_lu_60[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_138[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_61 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, 14, 14, 1024  263168      ['re_lu_61[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_139[0][0]']             \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_38 (Add)                   (None, 14, 14, 1024  0           ['re_lu_59[0][0]',               \n",
      "                                )                                 'batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_62 (ReLU)                (None, 14, 14, 1024  0           ['add_38[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, 14, 14, 256)  262400      ['re_lu_62[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_140[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_63 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, 14, 14, 256)  590080      ['re_lu_63[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_141[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_64 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, 14, 14, 1024  263168      ['re_lu_64[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_142[0][0]']             \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_39 (Add)                   (None, 14, 14, 1024  0           ['re_lu_62[0][0]',               \n",
      "                                )                                 'batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_65 (ReLU)                (None, 14, 14, 1024  0           ['add_39[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, 14, 14, 256)  262400      ['re_lu_65[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_143[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_66 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, 14, 14, 256)  590080      ['re_lu_66[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_144[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_67 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, 14, 14, 1024  263168      ['re_lu_67[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_145[0][0]']             \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 14, 14, 1024  0           ['re_lu_65[0][0]',               \n",
      "                                )                                 'batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_68 (ReLU)                (None, 14, 14, 1024  0           ['add_40[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, 14, 14, 256)  262400      ['re_lu_68[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_146[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_69 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, 14, 14, 256)  590080      ['re_lu_69[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_147[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_70 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, 14, 14, 1024  263168      ['re_lu_70[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_148[0][0]']             \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 14, 14, 1024  0           ['re_lu_68[0][0]',               \n",
      "                                )                                 'batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_71 (ReLU)                (None, 14, 14, 1024  0           ['add_41[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, 14, 14, 256)  262400      ['re_lu_71[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_149[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_72 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)            (None, 14, 14, 256)  590080      ['re_lu_72[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_150[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_73 (ReLU)                (None, 14, 14, 256)  0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)            (None, 14, 14, 1024  263168      ['re_lu_73[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 14, 14, 1024  4096       ['conv2d_151[0][0]']             \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 14, 14, 1024  0           ['re_lu_71[0][0]',               \n",
      "                                )                                 'batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_74 (ReLU)                (None, 14, 14, 1024  0           ['add_42[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)            (None, 7, 7, 512)    524800      ['re_lu_74[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_153[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_75 (ReLU)                (None, 7, 7, 512)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)            (None, 7, 7, 512)    2359808     ['re_lu_75[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_154[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_76 (ReLU)                (None, 7, 7, 512)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)            (None, 7, 7, 2048)   2099200     ['re_lu_74[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)            (None, 7, 7, 2048)   1050624     ['re_lu_76[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 7, 7, 2048)  8192        ['conv2d_152[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 7, 7, 2048)  8192        ['conv2d_155[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 7, 7, 2048)   0           ['batch_normalization_90[0][0]', \n",
      "                                                                  'batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_77 (ReLU)                (None, 7, 7, 2048)   0           ['add_43[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)            (None, 7, 7, 512)    1049088     ['re_lu_77[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_156[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_78 (ReLU)                (None, 7, 7, 512)    0           ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)            (None, 7, 7, 512)    2359808     ['re_lu_78[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_157[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_79 (ReLU)                (None, 7, 7, 512)    0           ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)            (None, 7, 7, 2048)   1050624     ['re_lu_79[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 7, 7, 2048)  8192        ['conv2d_158[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 7, 7, 2048)   0           ['re_lu_77[0][0]',               \n",
      "                                                                  'batch_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_80 (ReLU)                (None, 7, 7, 2048)   0           ['add_44[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)            (None, 7, 7, 512)    1049088     ['re_lu_80[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_159[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_81 (ReLU)                (None, 7, 7, 512)    0           ['batch_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)            (None, 7, 7, 512)    2359808     ['re_lu_81[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_160[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " re_lu_82 (ReLU)                (None, 7, 7, 512)    0           ['batch_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)            (None, 7, 7, 2048)   1050624     ['re_lu_82[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 7, 7, 2048)  8192        ['conv2d_161[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 7, 7, 2048)   0           ['re_lu_80[0][0]',               \n",
      "                                                                  'batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " re_lu_83 (ReLU)                (None, 7, 7, 2048)   0           ['add_45[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['re_lu_83[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1000)         2049000     ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import ZeroPadding2D\n",
    "vgg50_input = Input((224, 224, 3))\n",
    "\n",
    "X = layers.ZeroPadding2D(padding=(3, 3))(vgg50_input)\n",
    "X = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='valid')(X)\n",
    "X = layers.BatchNormalization()(X)\n",
    "X = layers.ReLU()(X)\n",
    "X = layers.ZeroPadding2D(padding=(1, 1))(X)\n",
    "X = layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2))(X)\n",
    "\n",
    "X = projection_block(64, input_X=X, stride=(1,1))\n",
    "\n",
    "for _ in range(2):\n",
    "    X = identity_block(64, X)\n",
    "X = projection_block(128, X)\n",
    "\n",
    "for _ in range(3):\n",
    "    X = identity_block(128, X)\n",
    "X = projection_block(256, X)\n",
    "\n",
    "for _ in range(5):\n",
    "    X = identity_block(256, X)\n",
    "\n",
    "X = projection_block(512, X)\n",
    "\n",
    "for _ in range(2):\n",
    "    X = identity_block(512, X)\n",
    "\n",
    "X = layers.GlobalAveragePooling2D()(X)\n",
    "\n",
    "vgg50_outputs = layers.Dense(1000, activation='softmax')(X)\n",
    "\n",
    "model = Model(vgg50_input, vgg50_outputs)\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ResNet50 v2 introduced preactivation batch normalization (BN-RE-Conv), in which the batch normalization and activation functions are placed before (instead of after) the corresponding convolution or dense layer. This has now become a common practice, as depicted here for implementation of the residual block with the identity link in v2:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def identity_block_v2(n_filters, input_X):\n",
    "    short_cut = X\n",
    "\n",
    "    hidden_X = BatchNormalization()(X)\n",
    "    hidden_X = ReLU()(hidden_X)\n",
    "    hidden_X = Conv2D(n_filters, kernel_size=(1,1), strides=(1,1))(hidden_X)\n",
    "\n",
    "    hidden_X = BatchNormalization()(hidden_X)\n",
    "    hidden_X = ReLU()(hidden_X)\n",
    "    hidden_X= Conv2D(n_filters, kernel_size=(3,3), strides=(1,1), padding=\"same\")(hidden_X)\n",
    "\n",
    "    hidden_X = BatchNormalization()(hidden_X)\n",
    "    hidden_X = ReLU()(hidden_X)\n",
    "    hidden_X = Conv2D(n_filters*4, kernel_size=(1,1), strides=(1, 1))(hidden_X)\n",
    "\n",
    "\n",
    "    hidden_X = layers.add([short_cut, hidden_X])\n",
    "\n",
    "    return hidden_X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "1. A convolutional neural network can be described as adding a frontend to a deep neural network.\n",
    "2. The purpose of the CNN frontend is to reduce the high-dimensional pixel input to low-dimensional feature representation.\n",
    "3. The lower dimensionality of the feature representation makes it practical to do deep learning with real-world images.\n",
    "4. Image resizing and pooling are used to reduce the number of parameters in the model, without information loss.\n",
    "5. Using a cascading set of filters to detect features has similarities to the human eye\n",
    "6. VGG formalized the concept of a convolutional pattern that is repeated.\n",
    "7. Residual networks introduced the concept of feature reuse and demonstrated the ability to obtain higher accuracy at the same number of layers as a VGG, and go deeper in layers for more accuracy.\n",
    "8. Batch normalization allowed models to go deeper in layers for more accuracy before being exposed to vanishing or exploding gradients.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}