{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Forward feeding and Backward propagation\n",
    "When training a model,\n",
    "1. You feed data forward through the model, and compute how incorrect the predicted results are — the loss.\n",
    "2. Then the loss is backward-propagated to make updates to the model’s parameters, which is what the model is learning—the values for the parameters.\n",
    "\n",
    "When training a model, you start with training data that’s representative of the target environment where the model will be deployed.\n",
    "\n",
    "That data, in other words, is a **sampling distribution** of a **population distribution**. The training data consists of example.\n",
    "\n",
    "\n",
    "Each example has two parts:\n",
    "1. the features, also referred to as independent variables; and\n",
    "2. corresponding labels, also referred to as the dependent variable.\n",
    "\n",
    "The labels are also known as the ground truths (the “correct answers”). It can accurately predict the label (the “correct answer”)—supervised learning. This\n",
    "step is known as inference.\n",
    "\n",
    "During training, we feed batches (also called samples) of the training data to the model through the input layer (also referred to as the bottom of the model). The training data is then transformed by the parameters (weights and biases) in the layers of the model as it moves forward toward the output nodes (also referred to as the top of the model). At the output nodes, we measure how far away we are from the “correct” answers, which, again, is called the loss. We then backward-propagate the loss through the layers of the models and update the parameters to be closer to getting the correct answer on the next batch.\n",
    "\n",
    "We continue to repeat this process until we reach convergence, which could be described as “this is as accurate as we can get on this training run.”\n",
    "\n",
    "## Feeding\n",
    "Feeding is the process of sampling batches from the training data and forward-feeding the batches through the model, and then calculating the loss at the output. A batch can be one or more examples from the training data chosen at random.\n",
    "\n",
    " The size of the batch is typically constant, which is referred to as the (mini) batch size. All the training data is split into batches, and typically each example will appear in only one batch.\n",
    "\n",
    " The size of the batch is typically constant, which is referred to as the (mini) batch size. All the training data is split into batches, and typically each example will appear in only one batch.\n",
    "\n",
    "<img src=\"img.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Backward propagation\n",
    "## Background\n",
    "updates to the weights of the output layer are relative to the loss in the prediction, updates to weights in earlier layers are\n",
    "relative to the updates in the next layer. Thus, the concept of backward propagation was formed.\n",
    "\n",
    "Many things were tried, with no improvements, until a technique was developed to update weights not to the amount of change in the next\n",
    "layer, but relative to the rate of change—hence the discovery and development of gradient descent techniques.\n",
    "\n",
    "## BATCH-BASED BACKWARD PROPAGATION\n",
    "\n",
    "After each batch of training data is forward-fed through the model and the loss is calculated, the loss is backward-propagated through the model. We go layer by layer updating the model’s parameters (weights and parameters), starting at the top layer (output) and moving toward the bottom layer (input). How the parameters are updated is a combination of the loss, the values of the current parameters, and the updates made to the proceeding layer.\n",
    "\n",
    "<img src=\"img_1.png\">"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}